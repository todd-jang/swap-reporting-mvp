1. 데이터 수집 및 적재 연동:

Vb fep 및 /data/yyyymmdd/rec: Vb fep (Front-End Processor)는 외부 소스로부터 스왑 데이터를 수신하여 특정 디렉터리 구조(/data/yyyymmdd/rec)의 파일 형태로 저장하는 역할을 합니다. 이는 배치(Batch)성 데이터 입력의 시작점입니다.
/data/yyyymmdd/rec -> TainTube: TainTube 구성 요소는 /data/.../rec 디렉터리에 저장된 파일들을 주기적으로 감지하거나 특정 이벤트에 의해 트리거되어 읽어옵니다. 이것이 TainTube의 주요 입력 경로입니다.
Vo fep -> stream -> TainOn: Vo fep는 다른 외부 소스로부터 스왑 데이터를 실시간 또는 스트림(Stream) 형태로 수신합니다. 이 스트림 데이터는 직접 TainOn 구성 요소로 전달됩니다. 이것이 TainOn의 주요 입력 경로이며, 실시간(Real-time) 또는 준실시간 데이터 처리를 위한 연동입니다.
TainTube -> DB (TB_BAT_FILE_MST, TB_BAT_FILE_HIST): TainTube는 읽어온 입력 파일의 데이터를 파싱하고 유효성을 검증한 후, 원본 데이터 또는 초기 검증된 데이터를 데이터베이스(예: TB_BAT_FILE_MST - 마스터 파일 기록, TB_BAT_FILE_HIST - 기록/로그)에 적재합니다. 파일 기반 입력 데이터의 1차 저장소 연동입니다.
TainOn -> DB (TB_ON_MST, TB_ON_HIST): TainOn은 수신한 실시간 스트림 데이터를 처리하고 필요한 변환/검증을 수행한 후, 처리된 데이터를 데이터베이스(예: TB_ON_MST - 온라인 마스터 테이블, TB_ON_HIST - 기록/로그)에 적재합니다. 실시간 입력 데이터의 저장소 연동입니다.
2. 데이터 처리 및 보고서 생성 연동:

DB (TB_BAT_FILE_MST 등) -> TainBat: TainBat (배치 처리) 구성 요소는 주기적으로 (예: 일별) 데이터베이스에 적재된 원본 데이터 또는 초기 처리된 데이터를 읽어옵니다.
TainBat -> DB (TB_ON_MST, TB_ON_HIST) 및 /data/yyyymmdd/send: TainBat는 읽어온 데이터를 CFTC 가이드라인에 따라 복잡한 변환, 집계, 연산 등을 수행한 후, 처리된/집계된 최종 데이터를 데이터베이스(예: TB_ON_MST, TB_ON_HIST)에 저장합니다. 또한, CFTC 보고서 형식에 맞는 최종 보고서 파일이나 전송할 데이터를 /data/.../send 디렉터리에 생성합니다. 이것이 TainBat의 주요 출력 연동입니다.
TainOn -> DB (TB_ON_MST, TB_ON_HIST): TainOn은 실시간 데이터 처리 후 결과를 DB에 저장할 뿐만 아니라, 온디맨드(On-demand) 보고서 요청이 들어오면 데이터베이스에 저장된 데이터를 읽어와 보고서를 생성하는 데 활용합니다.
3. API 서비스를 통한 접근 및 제어 연동:

외부 / TainWeb -> api -> Vb api svr / Vo api svr: 외부 사용자나 웹 UI (TainWeb)는 API Gateway 또는 직접 Vb api svr 및 Vo api svr와 HTTP/HTTPS 프로토콜 기반의 API 호출을 통해 상호작용합니다. 이것이 시스템 기능에 접근하는 주요 통로입니다.
api -> jwt -> Vb api svr / Vo api svr: Vb api svr와 Vo api svr는 수신된 API 요청에 대해 jwt (JSON Web Token) 기반의 인증 및 권한 부여를 수행합니다. 클라이언트가 제공한 토큰의 유효성을 검증하고 사용자의 접근 권한을 확인합니다.
Vb api svr -> DB: Vb api svr는 인증/권한 부여된 요청에 따라 데이터베이스에서 필요한 데이터를 조회하고 클라이언트에게 응답합니다 (예: 특정 스왑 데이터 조회).
Vo api svr -> DB: Vo api svr는 보고서 상태 조회와 같은 요청에 대해 데이터베이스에서 정보를 조회합니다.
Vo api svr -> TainBat / TainOn: Vo api svr는 사용자 요청(예: 보고서 생성 요청)에 따라 TainBat (배치) 또는 TainOn (온디맨드 보고서 생성) 구성 요소의 특정 기능을 트리거하는 역할을 할 수 있습니다. API 호출이 백그라운드 작업(배치)을 시작시키는 연동입니다.
/data/yyyymmdd/send -> Vo fep -> stream: TainBat가 생성한 보고서 파일은 /data/.../send 디렉터리에 저장됩니다. Vo fep는 이 파일을 읽어와 외부 시스템으로 스트림 형태로 전송하는 역할을 할 수 있습니다. 이것은 처리된 데이터를 외부로 다시 내보내는 (Outgestion) 연동입니다.
Vo api svr <- /data/yyyymmdd/send (추정): 다이어그램에 명시적 화살표는 없지만, Vo api svr가 생성된 보고서 파일을 다운로드하는 기능을 제공한다면 /data/.../send 디렉터리에서 파일을 읽어오는 연동이 있을 수 있습니다.
요약:

====================================================================================
실시간 스왑 데이터 처리를 포그라운드로 하여 GPU 서버 등 다른 서비스보다 우선하여 연산 처리하게 하는 방법은 다음과 같은 메커니즘들을 통해 실현됩니다. 이는 온프레미스 Kubernetes 클러스터나 NCP 클라우드 Kubernetes 클러스터 모두에 적용 가능하며, VM 환경에서도 일부 개념은 적용 가능합니다.

1. Kubernetes 환경에서의 우선순위 부여 (가장 일반적인 접근):

Kubernetes는 워크로드(Pod)에게 자원을 우선적으로 할당하고 실행될 수 있도록 다양한 메커니즘을 제공합니다.

자원 요청 및 제한 (Resource Requests and Limits):
실시간 데이터 처리 Pod(TainOn 등)는 CPU, 메모리, 그리고 필요한 경우 GPU에 대해 명확한 자원 요청(requests) 및 **자원 제한(limits)**을 설정합니다. requests: { cpu: "2", memory: "4Gi", nvidia.com/gpu: 1 }, limits: { cpu: "2", memory: "4Gi", nvidia.com/gpu: 1 } 와 같이 설정합니다.
스케줄러는 requests를 보고 해당 Pod를 실행할 충분한 자원이 있는 노드를 찾습니다. limits는 Pod가 사용할 수 있는 최대 자원량입니다.
QoS 클래스 (Quality of Service Classes):
Kubernetes는 Pod의 자원 요청/제한 설정에 따라 QoS 클래스를 부여합니다. Guaranteed 클래스는 requests와 limits가 동일하게 설정된 Pod에 부여되며, 가장 높은 수준의 서비스 품질을 보장받습니다 (자원 경합 시 가장 마지막에 종료됨).
실시간 데이터 처리 Pod를 Guaranteed 클래스로 설정하여 우선순위를 높입니다.
PriorityClass 및 선점 (Preemption):
PriorityClass는 Pod의 상대적인 중요도를 나타냅니다. 실시간 데이터 처리 Pod에 높은 PriorityClass를 할당합니다.
노드의 자원이 부족할 때, 스케줄러는 높은 Priority를 가진 Pod를 위해 낮은 Priority를 가진 Pod를 **선점(Preempt)**하여 해당 Pod를 종료시키고 높은 Priority Pod가 실행될 공간을 확보합니다. 이는 실시간 처리의 생존성을 보장하는 강력한 메커니즘입니다.
노드 셀렉터 / 어피니티 (Node Selector / Affinity):
실시간 데이터 처리 Pod는 필요한 자원(특히 GPU)이 있는 특정 노드 그룹(GPU 노드 풀 등)에만 배포되도록 nodeSelector 또는 affinity를 설정합니다.
HPA (Horizontal Pod Autoscaler):
실시간 데이터 처리 Pod의 부하(CPU/GPU 사용률, 네트워크 트래픽 등)에 따라 Pod 인스턴스 수를 자동으로 증가/감소하도록 HPA를 설정합니다. 이를 통해 실시간 처리 부하 증가 시 자동으로 자원을 확보하여 성능 저하를 방지합니다.
2. VM 환경에서의 우선순위 부여 (Kubernetes 미사용 시):

Kubernetes와 같은 오케스트레이션 도구를 사용하지 않고 VM에서 직접 서비스를 운영하는 경우, 우선순위 관리가 더 어렵고 수동적입니다.

VM 자원 할당: 실시간 데이터 처리 VM에 더 많은 vCPU, 메모리, GPU를 할당합니다.
OS 레벨 우선순위: 운영체제 자체의 프로세스 우선순위 설정을 사용합니다 (다른 VM과의 자원 경합 해결에는 한계).
워크로드 스케줄링: 배치 및 학습 작업과 같은 백그라운드 워크로드를 실시간 처리 시스템의 부하가 적은 시간대(예: 야간)에 실행되도록 수동으로 스케줄링합니다.
물리적/논리적 분리: 실시간 처리 VM과 백그라운드 VM을 물리적으로 또는 논리적으로 분리된 서버 그룹에 배치하여 자원 경합을 줄입니다 (하지만 이는 자원 활용 효율성을 저하시킬 수 있습니다).
3. 하이브리드/멀티클라우드 환경에서의 연동:

우선순위 메커니즘 자체는 각 클라우드 환경(NCP 클라우드 Kubernetes) 또는 온프레미스 환경(온프레미스 Kubernetes 또는 VM) 내에서 주로 작동합니다.

환경 간 연동: 온프레미스의 레거시 시스템에서 발생하는 실시간 데이터가 클라우드의 실시간 처리 시스템으로 전송되거나, 클라우드의 AI 학습 결과가 온프레미스 시스템으로 전달될 때, **환경 간 네트워크 연결(전용회선, 클라우드 Connect)**의 성능과 안정성이 중요합니다. 실시간 처리의 저지연 요구사항을 만족하기 위한 충분한 네트워크 대역폭과 낮은 지연 시간이 보장되어야 합니다.
분산 시스템 설계: 환경을 넘나드는 워크플로우는 메시지 큐 등을 사용하여 비동기적으로 설계하고, 각 환경 내에서는 해당 환경의 자원 관리/우선순위 메커니즘을 활용하여 안정성을 높입니다.
"마스터 노드에서 우선 처리"의 의미:

이러한 우선순위 관리의 핵심 주체는 물리적인 '마스터 노드'가 아니라, Kubernetes의 **컨트롤 플레인(특히 스케줄러 컴포넌트)**입니다. 컨트롤 플레인은 클러스터 전체의 자원 상태와 Pod들의 자원 요구사항, 우선순위 등을 파악하여 어떤 Pod를 어느 노드에 배치하고, 자원 부족 시 어떤 Pod를 선점할지 등을 결정하고 실행하는 역할을 합니다. 즉, '마스터 노드에서 우선 처리'한다는 것은 컨트롤 플레인이 설정된 우선순위 규칙에 따라 실시간 처리 워크로드를 다른 워크로드보다 우선하여 자원을 할당하고 실행되도록 관리한다는 개념으로 이해할 수 있습니다.

결론:

GPU 서버 등을 포함한 클라우드 및 온프레미스 환경에서 실시간 스왑 데이터 처리를 포그라운드로 우선 처리하게 하려면, Kubernetes와 같은 오케스트레이션 플랫폼을 활용하여 워크로드(Pod)별 자원 요청, QoS 클래스, PriorityClass, HPA 등을 정교하게 설정하는 것이 가장 효과적인 방법입니다. 이를 통해 스케줄러가 실시간 처리 Pod에게 우선적으로 자원을 할당하고, 필요한 경우 다른 백그라운드 Pod를 선점하여 자원을 확보하게 함으로써 포그라운드 워크로드의 성능과 안정성을 보장할 수 있습니다. 이는 VM 환경에서도 부분적으로 적용될 수 있지만, Kubernetes 환경에서 훨씬 체계적이고 자동화된 방식으로 관리할 수 있습니다.
이 아키텍처는 크게 데이터 수집/적재(Ingestion), 데이터 처리(Processing), **데이터 제공/제어(Serving/Control)**의 세 가지 주요 흐름을 가집니다.

데이터는 파일 또는 스트림 형태로 Vb fep / Vo fep를 통해 시스템에 진입합니다.
TainTube와 TainOn은 각각 파일 및 스트림 형태의 데이터를 초기 처리하고 데이터베이스에 적재합니다.
TainBat는 주기적으로 DB의 데이터를 읽어 복잡한 배치 처리를 수행하고 결과를 다시 DB나 파일로 저장합니다.
Vb api svr 및 Vo api svr는 인증을 거쳐 데이터를 조회하거나 보고서 생성과 같은 백그라운드 작업을 제어하는 API 인터페이스를 제공합니다.
처리된 보고서 파일은 Vo fep를 통해 외부로 전송될 수 있습니다.
이 모든 과정은 데이터베이스와 파일 시스템을 중심으로 데이터를 공유하고 상태를 관리하며 연동됩니다.
