# deployment/kubernetes/ui-backend.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: ui-backend-deployment
  labels:
    app: ui-backend
spec:
  replicas: 2 # 부하에 따라 인스턴스 수 (HPA로 자동 조절 가능)
  selector:
    matchLabels:
      app: ui-backend
  template:
    metadata:
      labels:
        app: ui-backend
    spec:
      # UI 백엔드는 일반적으로 중간 또는 낮은 우선순위
      # priorityClassName: medium-priority # 예시 PriorityClass 이름

      containers:
      - name: ui-backend
        image: your_docker_registry/ui-backend:latest # UI 백엔드 Docker 이미지 경로
        ports:
        - containerPort: 8000 # FastAPI 서비스 포트 (예시)
        # TODO: 필요한 환경 변수 설정 (예: DB 접속 정보, 다른 서비스 API URL)
        # env:
        #   - name: DATABASE_URL
        #     value: "postgresql://user:password@database-service:5432/dbname"
        #   - name: AI_INFERENCE_API_URL # UI 백엔드에서도 직접 AI 서비스 호출 시 (processing.py)
        #     value: http://ai-inference-service:8001

        resources:
          requests: # 요청 자원
            cpu: "500m" # 0.5 CPU 코어
            memory: "512Mi"

          limits: # 최대 사용 제한
            cpu: "1"
            memory: "1Gi"

        # TODO: Readiness Probe, Liveness Probe 설정

      # UI 백엔드는 GPU가 필요 없으므로 GPU 노드에 배포되지 않도록 설정 (선택 사항, 기본적으로 GPU 요청 안 하면 GPU 없는 노드에 배포)
      # nodeSelector:
      #   gpu.nvidia.com/present: "false" # GPU 없는 노드에만 배포 (레이블은 클러스터 설정에 따름)


---
# UI 백엔드를 위한 Service (외부 접근 허용 필요)
apiVersion: v1
kind: Service
metadata:
  name: ui-backend-service
spec:
  selector:
    app: ui-backend
  # 외부에서 접근 가능하도록 NodePort 또는 LoadBalancer 타입 사용
  type: LoadBalancer # 클라우드 환경에서 LoadBalancer 사용 예시
  # type: NodePort # 자체 Kubernetes 클러스터에서 NodePort 사용 예시
  ports:
  - protocol: TCP
    port: 80 # 외부에서 접근할 포트 (HTTP 기본 포트)
    targetPort: 8000 # Pod 컨테이너 포트
    # nodePort: 30000 # NodePort 타입 사용 시 특정 노드 포트 지정 가능
